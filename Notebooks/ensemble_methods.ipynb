{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods\n",
    "Ensemble methods is a machine learning technique that combines several base models in order to produce one optimal predictive model ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to do everything that we did before so refere to Linear-Regression notebook for explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'style', 'Exterior color', 'interior color', 'Engine',\n",
       "       'drive type', 'Fuel Type', 'Transmission', 'Mileage', 'mpg city',\n",
       "       'mpg highway', 'price', 'Year', 'Engine V', 'Brand'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars =  pd.read_csv(\"cleaned_data.csv\")\n",
    "cars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  cars[['Name', 'style', 'Exterior color', 'interior color', 'Engine',\n",
    "       'drive type', 'Fuel Type', 'Transmission', 'Mileage', 'mpg city',\n",
    "       'mpg highway', 'Year', 'Engine V', 'Brand']]\n",
    "\n",
    "\n",
    "Y = cars[\"price\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\")\n",
    "\n",
    "categorical_features = onehot.fit_transform(X.iloc[:, [1,4,5,6,7,13]]).toarray()\n",
    "X = np.delete(X.values, [0,1,2,3,4,5,6,7,13], 1)\n",
    "X = np.concatenate((X,categorical_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y,\n",
    "    test_size=0.1,\n",
    "    random_state=82\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor : \n",
    "\n",
    "A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\n",
    "<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">read full documentation</a>\n",
    "\n",
    "### GridSearch : \n",
    "Exhaustive search over specified parameter values for an estimator.<br>\n",
    "\n",
    "GridSearchCV implements a “fit” and a “score” method. It also implements “score_samples”, “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.\n",
    "\n",
    "The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.\n",
    "<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9042497957590709\n",
      "{'rfr__n_estimators': 94}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfr_pip = Pipeline([\n",
    "    #(\"standardizer\", StandardScaler()),\n",
    "    (\"rfr\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "param_range = [i for i in range(50,101)]\n",
    "grid_params = [{\"rfr__n_estimators\" : param_range}]\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    rfr_pip, \n",
    "    grid_params,\n",
    "    n_jobs=-1, \n",
    "    cv=5\n",
    ")\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see we used a pipeline for simplicity and used RandomForestRegressor for estimator. its not necessary to bring our features into same scale while we are using decision trees. but we have commented the code and you can use it if you want(the result will not change).<br><br>\n",
    "we used GridSearch to find the optimal value of n_estimators in RandomForestRegressor. as you can see we got a slightly better result than our previously trained linearregression model by using 94 seprate estimators.<br> <br>\n",
    "lets check the goodness of our models fit on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.9130364773665023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "rfr = grid.best_estimator_\n",
    "rfr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rfr.predict(x_test)\n",
    "print(f\"Test Accuracy : {r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see our model performs well on either train data or test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sina Kazemi<br>\n",
    "Github : <a href=\"https://github.com/sina96n/\">sina96n</a>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
