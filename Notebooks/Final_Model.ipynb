{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading dataset with pandas library using **read_csv** function and see what our dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>style</th>\n",
       "      <th>Exterior color</th>\n",
       "      <th>interior color</th>\n",
       "      <th>Engine</th>\n",
       "      <th>drive type</th>\n",
       "      <th>Fuel Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>mpg city</th>\n",
       "      <th>mpg highway</th>\n",
       "      <th>price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine V</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titan</td>\n",
       "      <td>Pickup Truck</td>\n",
       "      <td>Deep Blue Pearl</td>\n",
       "      <td>Black</td>\n",
       "      <td>V-8 Gas</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>82230</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>35620</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Nissan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civic</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Sonic Gray Pearl</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Inline-4 Gas Turbocharged</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>24282</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>24999</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charger</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Indigo Blue</td>\n",
       "      <td>Brazen Gold/Black</td>\n",
       "      <td>V-8 Gas</td>\n",
       "      <td>RWD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>19468</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>41999</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Dodge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F-150</td>\n",
       "      <td>Pickup Truck</td>\n",
       "      <td>Shadow Black</td>\n",
       "      <td>Medium Earth Gray</td>\n",
       "      <td>V-6 Gas Turbocharged</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>195205</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>20995</td>\n",
       "      <td>2018</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Altima</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>White</td>\n",
       "      <td>Black</td>\n",
       "      <td>Inline-4 Gas</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>92366</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>10995</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Nissan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name         style    Exterior color     interior color  \\\n",
       "0    Titan  Pickup Truck   Deep Blue Pearl              Black   \n",
       "1    Civic     Hatchback  Sonic Gray Pearl            Unknown   \n",
       "2  Charger         Sedan       Indigo Blue  Brazen Gold/Black   \n",
       "3    F-150  Pickup Truck      Shadow Black  Medium Earth Gray   \n",
       "4   Altima         Sedan             White              Black   \n",
       "\n",
       "                      Engine drive type Fuel Type Transmission  Mileage  \\\n",
       "0                    V-8 Gas        4WD       Gas    Automatic    82230   \n",
       "1  Inline-4 Gas Turbocharged        FWD       Gas    Automatic    24282   \n",
       "2                    V-8 Gas        RWD       Gas    Automatic    19468   \n",
       "3       V-6 Gas Turbocharged        4WD       Gas    Automatic   195205   \n",
       "4               Inline-4 Gas        FWD       Gas    Automatic    92366   \n",
       "\n",
       "   mpg city  mpg highway  price  Year  Engine V   Brand  \n",
       "0        15           21  35620  2018       5.6  Nissan  \n",
       "1        31           40  24999  2020       1.5   Honda  \n",
       "2        16           25  41999  2018       5.7   Dodge  \n",
       "3        18           23  20995  2018       2.7    Ford  \n",
       "4        27           38  10995  2015       2.5  Nissan  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars =  pd.read_csv(\"cleaned_data.csv\")\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exporting column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'style', 'Exterior color', 'interior color', 'Engine',\n",
       "       'drive type', 'Fuel Type', 'Transmission', 'Mileage', 'mpg city',\n",
       "       'mpg highway', 'price', 'Year', 'Engine V', 'Brand'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we ae going to create our X and Y data in order to perform the processes that have been told in the first part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  cars[['Name', 'style', 'Exterior color', 'interior color', 'Engine',\n",
    "       'drive type', 'Fuel Type', 'Transmission', 'Mileage', 'mpg city',\n",
    "       'mpg highway', 'Year', 'Engine V', 'Brand']]\n",
    "\n",
    "\n",
    "Y = cars[\"price\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode categorical features as a one-hot numeric array.\n",
    "The input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme. This creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse parameter)<br><br>\n",
    "\n",
    "By default, the encoder derives the categories based on the unique values in each feature. Alternatively, you can also specify the categories manually.<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\")\n",
    "\n",
    "categorical_features = onehot.fit_transform(X.iloc[:, [1,4,5,6,7,13]]).toarray()\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6532, 91)\n"
     ]
    }
   ],
   "source": [
    "print(categorical_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this part we are going to delete unnecessary features and the categorical features that we have encoded in the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6532, 5)\n"
     ]
    }
   ],
   "source": [
    "X = np.delete(X.values, [0,1,2,3,4,5,6,7,13], 1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we combine remaining features with the encoded array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6532, 96)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X,categorical_features), axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split arrays or matrices into train and test subsets.\n",
    "Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y,\n",
    "    test_size=0.1,\n",
    "    random_state=82,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor : \n",
    "\n",
    "A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\n",
    "<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">read full documentation</a>\n",
    "\n",
    "### GridSearch : \n",
    "Exhaustive search over specified parameter values for an estimator.<br>\n",
    "\n",
    "GridSearchCV implements a “fit” and a “score” method. It also implements “score_samples”, “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.\n",
    "\n",
    "The parameters of the estimator used to apply these methods are optimized by cross-validated grid-search over a parameter grid.\n",
    "<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046922991577464\n",
      "{'rfr__n_estimators': 96}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfr_pip = Pipeline([\n",
    "    #(\"standardizer\", StandardScaler()),\n",
    "    (\"rfr\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "param_range = [i for i in range(50,101)]\n",
    "grid_params = [{\"rfr__n_estimators\" : param_range}]\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    rfr_pip, \n",
    "    grid_params,\n",
    "    n_jobs=-1, \n",
    "    cv=5\n",
    ")\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see we used a pipeline for simplicity and used RandomForestRegressor for estimator. its not necessary to bring our features into same scale while we are using decision trees. but we have commented the code and you can use it if you want(the result will not change).<br><br>\n",
    "we used GridSearch to find the optimal value of n_estimators in RandomForestRegressor. as you can see we got a slightly better result than our previously trained linearregression model by using 94 seprate estimators.<br> <br>\n",
    "lets check the goodness of our models fit on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# obtaining the best estimator from grid\n",
    "rfr = grid.best_estimator_\n",
    "rfr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rfr.predict(x_test)\n",
    "print(\"Test Accuracy : {:.3f}\".format(r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we've got 91.4 percent accuracy that is a good amount for this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sina Kazemi<br>\n",
    "Github : <a href=\"https://github.com/sina96n/\">sina96n</a>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
