{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473a7313",
   "metadata": {},
   "source": [
    "# Linear Regression \n",
    "In statistics, linear regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables (also known as dependent and independent variables). The case of one explanatory variable is called simple linear regression; for more than one, the process is called multiple linear regression. This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable. <a href=\"https://en.wikipedia.org/wiki/Linear_regression\">read more</a><br><br>\n",
    "\n",
    "in this notebook we are going to train a linear regression model with our data. the overall process is : \n",
    "1. encode ordinal and nominal features with scikit-learn encoders.\n",
    "2. bring data into the same scale with scikit-learn feature scalers.\n",
    "3. split our dataset into train and test parts.\n",
    "4. fit our model with train data and evaluate the goodness of our fit with test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f708e2",
   "metadata": {},
   "source": [
    "importing needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2525f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ac9c8",
   "metadata": {},
   "source": [
    "reading dataset with pandas library using **read_csv** function and see what our dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdb95d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>style</th>\n",
       "      <th>Exterior color</th>\n",
       "      <th>interior color</th>\n",
       "      <th>Engine</th>\n",
       "      <th>drive type</th>\n",
       "      <th>Fuel Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>mpg city</th>\n",
       "      <th>mpg highway</th>\n",
       "      <th>price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine V</th>\n",
       "      <th>Brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titan</td>\n",
       "      <td>Pickup Truck</td>\n",
       "      <td>Deep Blue Pearl</td>\n",
       "      <td>Black</td>\n",
       "      <td>V-8 Gas</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>82230</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>35620</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Nissan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civic</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>Sonic Gray Pearl</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Inline-4 Gas Turbocharged</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>24282</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>24999</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charger</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Indigo Blue</td>\n",
       "      <td>Brazen Gold/Black</td>\n",
       "      <td>V-8 Gas</td>\n",
       "      <td>RWD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>19468</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>41999</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Dodge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F-150</td>\n",
       "      <td>Pickup Truck</td>\n",
       "      <td>Shadow Black</td>\n",
       "      <td>Medium Earth Gray</td>\n",
       "      <td>V-6 Gas Turbocharged</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>195205</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>20995</td>\n",
       "      <td>2018</td>\n",
       "      <td>2.7</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Altima</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>White</td>\n",
       "      <td>Black</td>\n",
       "      <td>Inline-4 Gas</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Gas</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>92366</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>10995</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Nissan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name         style    Exterior color     interior color  \\\n",
       "0    Titan  Pickup Truck   Deep Blue Pearl              Black   \n",
       "1    Civic     Hatchback  Sonic Gray Pearl            Unknown   \n",
       "2  Charger         Sedan       Indigo Blue  Brazen Gold/Black   \n",
       "3    F-150  Pickup Truck      Shadow Black  Medium Earth Gray   \n",
       "4   Altima         Sedan             White              Black   \n",
       "\n",
       "                      Engine drive type Fuel Type Transmission  Mileage  \\\n",
       "0                    V-8 Gas        4WD       Gas    Automatic    82230   \n",
       "1  Inline-4 Gas Turbocharged        FWD       Gas    Automatic    24282   \n",
       "2                    V-8 Gas        RWD       Gas    Automatic    19468   \n",
       "3       V-6 Gas Turbocharged        4WD       Gas    Automatic   195205   \n",
       "4               Inline-4 Gas        FWD       Gas    Automatic    92366   \n",
       "\n",
       "   mpg city  mpg highway  price  Year  Engine V   Brand  \n",
       "0        15           21  35620  2018       5.6  Nissan  \n",
       "1        31           40  24999  2020       1.5   Honda  \n",
       "2        16           25  41999  2018       5.7   Dodge  \n",
       "3        18           23  20995  2018       2.7    Ford  \n",
       "4        27           38  10995  2015       2.5  Nissan  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars =  pd.read_csv(\"cleaned_data.csv\")\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb47fa",
   "metadata": {},
   "source": [
    "exporting column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2704d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'style', 'Exterior color', 'interior color', 'Engine',\n",
       "       'drive type', 'Fuel Type', 'Transmission', 'Mileage', 'mpg city',\n",
       "       'mpg highway', 'price', 'Year', 'Engine V', 'Brand'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee896bbb",
   "metadata": {},
   "source": [
    "now we ae going to create our X and Y data in order to perform the processes that have been told in the first part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "567dcc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  cars[['Name', 'style', 'Exterior color', 'interior color', 'Engine',\n",
    "       'drive type', 'Fuel Type', 'Transmission', 'Mileage', 'mpg city',\n",
    "       'mpg highway', 'Year', 'Engine V', 'Brand']]\n",
    "\n",
    "\n",
    "Y = cars[\"price\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf1b711",
   "metadata": {},
   "source": [
    "#### Encode categorical features as a one-hot numeric array.\n",
    "The input to this transformer should be an array-like of integers or strings, denoting the values taken on by categorical (discrete) features. The features are encoded using a one-hot (aka ‘one-of-K’ or ‘dummy’) encoding scheme. This creates a binary column for each category and returns a sparse matrix or dense array (depending on the sparse parameter)<br><br>\n",
    "\n",
    "By default, the encoder derives the categories based on the unique values in each feature. Alternatively, you can also specify the categories manually.<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "639cdebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder(categories=\"auto\", handle_unknown=\"ignore\")\n",
    "\n",
    "categorical_features = onehot.fit_transform(X.iloc[:, [1,4,5,6,7,13]]).toarray()\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7ff99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6532, 91)\n"
     ]
    }
   ],
   "source": [
    "print(categorical_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae05e88",
   "metadata": {},
   "source": [
    "in this part we are going to delete unnecessary features and the categorical features that we have encoded in the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14a6d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6532, 5)\n"
     ]
    }
   ],
   "source": [
    "X = np.delete(X.values, [0,1,2,3,4,5,6,7,13], 1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c08bf",
   "metadata": {},
   "source": [
    "now we combine remaining features with the encoded array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d1da91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6532, 96)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X,categorical_features), axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f444f3",
   "metadata": {},
   "source": [
    "#### Split arrays or matrices into train and test subsets.\n",
    "Quick utility that wraps input validation and next(ShuffleSplit().split(X, y)) and application to input data into a single call for splitting (and optionally subsampling) data in a oneliner.<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "639a7ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y,\n",
    "    test_size=0.1,\n",
    "    random_state=82,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83392456",
   "metadata": {},
   "source": [
    "#### Standardize features by removing the mean and scaling to unit variance.\n",
    "The standard score of a sample x is calculated as:\n",
    "<br><br>\n",
    "z = (x - u) / s\n",
    "<br><br>\n",
    "where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.\n",
    "<br><br>\n",
    "Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used on later data using transform.\n",
    "<br><br>\n",
    "Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance).<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d9c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(x_train)\n",
    "\n",
    "x_train_std = std_scaler.transform(x_train)\n",
    "x_test_std  = std_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d1c1f9",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "LinearRegression fits a linear model with coefficients w = (w1, …, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.\n",
    "<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dcfde16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8627732275821445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lr = LinearRegression(fit_intercept=True, normalize=\"deprecated\")\n",
    "lr.fit(x_train_std, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(x_test_std)\n",
    "print(r2_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aede17",
   "metadata": {},
   "source": [
    "### Ridge : Linear least squares with l2 regularization.\n",
    "\n",
    "Minimizes the objective function:\n",
    "<br><br>\n",
    "||y - Xw||^2_2 + alpha * ||w||^2_2\n",
    "<br><br>\n",
    "This model solves a regression model where the loss function is the linear least squares function and regularization is given by the l2-norm. Also known as Ridge Regression or Tikhonov regularization. This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape (n_samples, n_targets)).<br>\n",
    "> Technically the Lasso model is optimizing the same objective function as the Elastic Net with alpha=1.0 (no L1 penalty).\n",
    "\n",
    "<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37ad74f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.862553379277978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(x_train_std, y_train)\n",
    "\n",
    "y_pred_ri = ridge = ridge.predict(x_test_std)\n",
    "print(r2_score(y_test, y_pred_ri))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a14d58a",
   "metadata": {},
   "source": [
    "### Lasso :\n",
    "Linear Model trained with L1 prior as regularizer.<br>\n",
    "> Technically the Lasso model is optimizing the same objective function as the Elastic Net with l1_ratio=1.0 (no L2 penalty).\n",
    "\n",
    "<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34e5b8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.862544427139954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=1, max_iter=20000)\n",
    "lasso.fit(x_train_std, y_train)\n",
    "\n",
    "y_pred_ls = lasso.predict(x_test_std)\n",
    "print(r2_score(y_test, y_pred_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fea4cf",
   "metadata": {},
   "source": [
    "### ElasticNet :\n",
    "\n",
    "Linear regression with combined L1 and L2 priors as regularizer.\n",
    "<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8e3cc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8014088417173381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic = ElasticNet(alpha=1, l1_ratio=0.5)\n",
    "elastic.fit(x_train_std, y_train)\n",
    "\n",
    "y_pred_el = elastic.predict(x_test_std)\n",
    "print(r2_score(y_test, y_pred_el))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf30918",
   "metadata": {},
   "source": [
    "so we have created linear regression models with and without l1 and l2 penalties and saw that they dont bring us a better result than a linear regression without penalty except the ElasticNet regressor that used too much penalty in order to reduce the rate of ovrfitting. in the next parts we are going to use different methods and tune hyperparameters to see if we can get a higher accuracy or not. but before that lets use pipeline for more simplified code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bbcaf0",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "Sequentially apply a list of transforms and a final estimator. Intermediate steps of the pipeline must be ‘transforms’, that is, they must implement fit and transform methods. The final estimator only needs to implement fit. The transformers in the pipeline can be cached using memory argument.\n",
    "<br><br>\n",
    "The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters. For this, it enables setting parameters of the various steps using their names and the parameter name separated by a '__', as in the example below. A step’s estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting it to 'passthrough' or None.\n",
    "<br><a href=\"https://scikit-learn.org/stable/modules/generated/sklearnpreprocessingOneHotEncoder.html\">read full documentation</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72b20e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pip_lr = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearRegression(fit_intercept=True, normalize=\"deprecated\")\n",
    ")\n",
    "pip_lr.fit(x_train_std, y_train)\n",
    "h_pred = pip_lr.predict(x_test)\n",
    "print(\"Test Accuracy : {:.3f}\".format(pip_lr.score(x_test_std, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aa1a84",
   "metadata": {},
   "source": [
    "Sina Kazemi<br>\n",
    "Github : <a href=\"https://github.com/sina96n/\">sina96n</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
